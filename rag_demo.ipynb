{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b991a96-c7f2-49cf-b12e-39f21ee3f6df",
   "metadata": {},
   "source": [
    "# RAG ````(Retrieval Augmented Generation)```` Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca75fc9-c8a9-43ae-b239-0acc003fb22d",
   "metadata": {},
   "source": [
    "### Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3902ab7-718f-4237-8b47-2de988671bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import chromadb as Db\n",
    "from chromadb.utils import embedding_functions\n",
    "from openai import OpenAI, AuthenticationError\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from  langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a18e9-a33d-4878-9771-6a46da597d92",
   "metadata": {},
   "source": [
    "### ```Connect to OpenAI LLM```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a8d886a-a8fc-4ba7-8ec5-7332c04889d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMMClient():\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.OPENAI_API_KEY=os.environ['API_KEY']\n",
    "        \n",
    "    def get_llm_client(self ):\n",
    "        try:\n",
    "            return OpenAI(api_key=OPENAI_API_KEY)\n",
    "        except:\n",
    "            print('Key is incorrect! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06c1e02-0b1e-412b-91df-fdb15ac02ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is incorrect! \n"
     ]
    }
   ],
   "source": [
    "llm_client:OpenAI=LMMClient().get_llm_client()\n",
    "# print(llm_client.get_api_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d510a79-4ce6-43cd-bedc-91f13b9c9aa0",
   "metadata": {},
   "source": [
    "### ``` Read and chunk document ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b8e6a2e-7baf-4fb8-8709-33379258d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "pdf=PdfReader('data/DsTree.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3550ee93-5c5c-44ea-8fe0-0e4654b4d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textSpliter(txt):\n",
    "    chunk_size=1000\n",
    "    chunk_overlap=200\n",
    "    spliter=RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap,   length_function=len)\n",
    "    return spliter.create_documents([txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6f48b0-6c16-4160-8f7e-ce1c8bfd75a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m chunks=textSpliter(\u001B[43mreport_text\u001B[49m)\n\u001B[32m      2\u001B[39m chunks\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# print(chunks)\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'report_text' is not defined"
     ]
    }
   ],
   "source": [
    "chunks=textSpliter(report_text)\n",
    "chunks\n",
    "# print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8f361d53-eec7-4120-94e9-7b07a78efa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_obj:OpenAIEmbeddings=LMMClient().embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a4305d75-dcbe-48c4-96ee-713e9399c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Vector db\n",
    "vectorstore = Chroma(\"RAG_STORE\", embeddings_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a02d72f1-1bb4-4650-b679-c4aae49e8707",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRateLimitError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[166]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mvectorstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:288\u001B[39m, in \u001B[36mVectorStore.add_documents\u001B[39m\u001B[34m(self, documents, **kwargs)\u001B[39m\n\u001B[32m    286\u001B[39m     texts = [doc.page_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[32m    287\u001B[39m     metadatas = [doc.metadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[32m--> \u001B[39m\u001B[32m288\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    289\u001B[39m msg = (\n\u001B[32m    290\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m`add_documents` and `add_texts` has not been implemented \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    291\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfor \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    292\u001B[39m )\n\u001B[32m    293\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(msg)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001B[39m, in \u001B[36mChroma.add_texts\u001B[39m\u001B[34m(self, texts, metadatas, ids, **kwargs)\u001B[39m\n\u001B[32m    275\u001B[39m texts = \u001B[38;5;28mlist\u001B[39m(texts)\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._embedding_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m     embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embedding_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m metadatas:\n\u001B[32m    279\u001B[39m     \u001B[38;5;66;03m# fill metadatas with empty dicts if somebody\u001B[39;00m\n\u001B[32m    280\u001B[39m     \u001B[38;5;66;03m# did not specify metadata for all texts\u001B[39;00m\n\u001B[32m    281\u001B[39m     length_diff = \u001B[38;5;28mlen\u001B[39m(texts) - \u001B[38;5;28mlen\u001B[39m(metadatas)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001B[39m, in \u001B[36mOpenAIEmbeddings.embed_documents\u001B[39m\u001B[34m(self, texts, chunk_size)\u001B[39m\n\u001B[32m    668\u001B[39m \u001B[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001B[39;00m\n\u001B[32m    669\u001B[39m \u001B[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001B[39;00m\n\u001B[32m    670\u001B[39m engine = cast(\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mself\u001B[39m.deployment)\n\u001B[32m--> \u001B[39m\u001B[32m671\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_len_safe_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    672\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunk_size\u001B[49m\n\u001B[32m    673\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001B[39m, in \u001B[36mOpenAIEmbeddings._get_len_safe_embeddings\u001B[39m\u001B[34m(self, texts, engine, chunk_size)\u001B[39m\n\u001B[32m    495\u001B[39m batched_embeddings: List[List[\u001B[38;5;28mfloat\u001B[39m]] = []\n\u001B[32m    496\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _iter:\n\u001B[32m--> \u001B[39m\u001B[32m497\u001B[39m     response = \u001B[43membed_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43m_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_invocation_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    502\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m    503\u001B[39m         response = response.dict()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001B[39m, in \u001B[36membed_with_retry\u001B[39m\u001B[34m(embeddings, **kwargs)\u001B[39m\n\u001B[32m    118\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001B[39;00m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_openai_v1():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43membeddings\u001B[49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    121\u001B[39m retry_decorator = _create_retry_decorator(embeddings)\n\u001B[32m    123\u001B[39m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_embed_with_retry\u001B[39m(**kwargs: Any) -> Any:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001B[39m, in \u001B[36mEmbeddings.create\u001B[39m\u001B[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m             embedding.embedding = np.frombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[32m    127\u001B[39m                 base64.b64decode(data), dtype=\u001B[33m\"\u001B[39m\u001B[33mfloat32\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    128\u001B[39m             ).tolist()\n\u001B[32m    130\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[32m--> \u001B[39m\u001B[32m132\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/embeddings\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    134\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    135\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\openai\\_base_client.py:1259\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1245\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1246\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1247\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1254\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1255\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1256\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1257\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\codes\\ML\\ragDemo\\rag_env\\Lib\\site-packages\\openai\\_base_client.py:1047\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1044\u001B[39m             err.response.read()\n\u001B[32m   1046\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1047\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mRateLimitError\u001B[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "vectorstore.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d8c0d-4dcd-4537-a12c-89d86619687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13ee54-00a7-4552-a0ce-65998061317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prompt to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d43b40-cc7a-40e4-b2e5-dc6e9c7657a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute PRomote and get resposne from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e29a2-8ad5-4800-ad90-8ac984038498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
